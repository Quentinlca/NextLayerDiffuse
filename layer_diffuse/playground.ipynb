{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc28242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mquentinlca\u001b[0m (\u001b[33mquentinlca-perso\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "d:\\Programmes\\miniconda3\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "d:\\quent\\Documents\\Copenhague\\Stage\\Recherche\\diffusion_research\\layer_diffuse\\training_outputs/DDPMNextTokenV2 is already a clone of https://huggingface.co/QLeca/DDPMNextTokenV2. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "Checked out main from main.\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline initialized on device :  cuda\n"
     ]
    }
   ],
   "source": [
    "from data_loaders import ModularCharatersDataLoader\n",
    "from models import DDPMNextTokenV2\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "\n",
    "train_dataloader = ModularCharatersDataLoader.get_modular_char_dataloader(dataset_name='QLeca/modular_characters_small',\n",
    "                                                                            split='train',\n",
    "                                                                            image_size=128,\n",
    "                                                                            batch_size=16,\n",
    "                                                                            shuffle=True)\n",
    "dataset = load_dataset('QLeca/modular_characters_small', \n",
    "                       split='train')\n",
    "\n",
    "prompts = dataset['prompt']\n",
    "vocab = list(dict.fromkeys(prompts))\n",
    "vocab = sorted(vocab)\n",
    "vocab = dict(zip(vocab, range(len(vocab))))\n",
    "pipeline = DDPMNextTokenV2.DDPMNextTokenV2Pipeline()\n",
    "pipeline.set_class_vocabulary(vocab.keys())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c7d96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 4/50 [00:48<09:13, 12.03s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m labels \u001b[38;5;241m=\u001b[39m get_class_labels(prompts)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Add a dimension for class labels\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(labels\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mclass_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Just run one batch for demonstration purposes\u001b[39;00m\n",
      "File \u001b[1;32md:\\Programmes\\miniconda3\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\quent\\Documents\\Copenhague\\Stage\\Recherche\\diffusion_research\\layer_diffuse\\models\\DDPMNextTokenV2.py:137\u001b[0m, in \u001b[0;36m__call__\u001b[1;34m(self, input_images, class_labels, num_inference_steps)\u001b[0m\n\u001b[0;32m    134\u001b[0m class_labels \u001b[38;5;241m=\u001b[39m class_labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mset_timesteps(num_inference_steps)\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mtimesteps\u001b[38;5;241m.\u001b[39mnumpy()):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# Get prediction of noise\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     noisy_samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([input_images, xt], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    140\u001b[0m     time_step \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(t, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_class_labels(prompts:list[str]) -> torch.Tensor:\n",
    "    class_labels = []\n",
    "    for prompt in prompts:\n",
    "        if prompt in vocab:\n",
    "            class_labels.append(vocab[prompt])\n",
    "        else:\n",
    "            class_labels.append(-1)  # Use -1 for unknown classes\n",
    "    return torch.tensor(class_labels, dtype=torch.long)\n",
    "\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    input_images = batch['input']\n",
    "    target_images = batch['target']\n",
    "    prompts = batch['prompt']\n",
    "    labels = get_class_labels(prompts).unsqueeze(1)  # Add a dimension for class labels\n",
    "    print(labels.shape)\n",
    "    outputs = pipeline(input_images=input_images,\n",
    "                       class_labels=labels)\n",
    "    \n",
    "    break  # Just run one batch for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee287956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
